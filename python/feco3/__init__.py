from __future__ import annotations
from dataclasses import dataclass
from functools import cached_property

import os
from typing import TYPE_CHECKING


from . import _version
from . import _feco3

if TYPE_CHECKING:
    import pyarrow as pa

__version__ = _version.get_version()


@dataclass
class Header:
    fec_version: str
    software_name: str
    software_version: str | None
    report_id: str | None
    report_number: str | None


@dataclass
class Cover:
    form_type: str
    filer_committee_id: str


class FecFile:
    def __init__(self, src: str | os.PathLike) -> None:
        """Create a new FecFile instance.

        Args:
            src: The path to the FEC file to parse.
        """
        self._src = src
        # An instance of _feco3.FecFile, which is the class generated by pyo3
        self._wrapped = _feco3.FecFile.from_path(src)

    @cached_property
    def header(self) -> Header:
        h = self._wrapped.header
        return Header(
            fec_version=h.fec_version,
            software_name=h.software_name,
            software_version=h.software_version,
            report_id=h.report_id,
            report_number=h.report_number,
        )

    @cached_property
    def cover(self) -> Cover:
        c = self._wrapped.cover
        return Cover(
            form_type=c.form_type,
            filer_committee_id=c.filer_committee_id,
        )

    def __repr__(self) -> str:
        src_str = f"src={self._src!r}"
        return f"{self.__class__.__name__}({src_str})"


class ParquetProcessor:
    def __init__(self, out_dir: str | os.PathLike) -> None:
        self._wrapped = _feco3.ParquetProcessor(out_dir)

    def process(self, fec_file: FecFile) -> None:
        self._wrapped.process(fec_file._wrapped)


# This is what rust parquet uses as a batch size
# https://docs.rs/parquet/40.0.0/src/parquet/file/properties.rs.html#83
# DEFAULT_PYARROW_RECORD_BATCH_MAX_SIZE = 1024 * 1024
DEFAULT_PYARROW_RECORD_BATCH_MAX_SIZE = 1024 * 1024


class PyarrowProcessor:
    def __init__(self, max_batch_size: int | None = None):
        if max_batch_size is None:
            max_batch_size = DEFAULT_PYARROW_RECORD_BATCH_MAX_SIZE
        self._wrapped = _feco3.PyarrowProcessor(max_batch_size)

    def next_batch(self, fec_file: FecFile) -> pa.RecordBatch:
        return self._wrapped.next_batch(fec_file._wrapped)
